{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7005d4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probably more imports than are really necessary...\n",
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchaudio.transforms import MelSpectrogram, AmplitudeToDB\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import numpy as np\n",
    "import miditoolkit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score, average_precision_score, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import models\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48503b3f",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "255b620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy1(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e56e40fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy2(groundtruth, predictions):\n",
    "    correct = 0\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        if predictions[k] == groundtruth[k]:\n",
    "            correct += 1\n",
    "    return correct / len(groundtruth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f190f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAGS = ['rock', 'oldies', 'jazz', 'pop', 'dance',  'blues',  'punk', 'chill', 'electronic', 'country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b772218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy3(groundtruth, predictions):\n",
    "    preds, targets = [], []\n",
    "    for k in groundtruth:\n",
    "        if not (k in predictions):\n",
    "            print(\"Missing \" + str(k) + \" from predictions\")\n",
    "            return 0\n",
    "        prediction = [1 if tag in predictions[k] else 0 for tag in TAGS]\n",
    "        target = [1 if tag in groundtruth[k] else 0 for tag in TAGS]\n",
    "        preds.append(prediction)\n",
    "        targets.append(target)\n",
    "    \n",
    "    mAP = average_precision_score(targets, preds, average='macro')\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6487755c",
   "metadata": {},
   "source": [
    "## Task 1: Composer classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9fdbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot1 = \"student_files/task1_composer_classification/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b686224",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model1():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def features(self, path):\n",
    "        filepath = path if os.path.exists(path) else os.path.join(dataroot1, path)\n",
    "        midi_obj = miditoolkit.midi.parser.MidiFile(filepath)\n",
    "        # midi_obj = miditoolkit.midi.parser.MidiFile(dataroot1 + '/' + path)\n",
    "        notes = midi_obj.instruments[0].notes\n",
    "        if not notes:\n",
    "            return [0] * 4 + [0] * 12 # handle empty case\n",
    "\n",
    "        num_notes = len(notes)\n",
    "        pitches = [note.pitch for note in notes]\n",
    "        durations = [note.end - note.start for note in notes]\n",
    "        total_time = max(note.end for note in notes) - min(note.start for note in notes)\n",
    "        \n",
    "        average_pitch = sum([note.pitch for note in notes]) / num_notes\n",
    "        std_pitch = np.std([note.pitch for note in notes])\n",
    "        average_duration = sum([note.end - note.start for note in notes]) / num_notes\n",
    "        std_duration = np.std(durations)\n",
    "        note_density = num_notes / total_time if total_time > 0 else 0\n",
    "        pitch_range = max(pitches) - min(pitches)\n",
    "\n",
    "        # Pitch class histogram\n",
    "        pitch_classes = [note.pitch % 12 for note in notes]\n",
    "        hist = [0] * 12\n",
    "        for pc in pitch_classes:\n",
    "            hist[pc] += 1\n",
    "        hist = [x / num_notes for x in hist] # normalize\n",
    "\n",
    "        # interval histogram\n",
    "        intervals = [pitches[i+1] - pitches[i] for i in range(len(pitches)-1)]\n",
    "        hist_intervals = [0] * 5\n",
    "        for interval in intervals:\n",
    "            if interval < -6:\n",
    "                hist_intervals[0] += 1\n",
    "            elif interval < 0:\n",
    "                hist_intervals[1] += 1\n",
    "            elif interval == 0:\n",
    "                hist_intervals[2] += 1\n",
    "            elif interval <= 6:\n",
    "                hist_intervals[3] += 1\n",
    "            else:\n",
    "                hist_intervals[4] += 1\n",
    "\n",
    "        if intervals:\n",
    "            hist_intervals = [x / len(intervals) for x in hist_intervals]\n",
    "        else:\n",
    "            hist_intervals = [0] * 5\n",
    "\n",
    "\n",
    "        # symbolic features\n",
    "        unique_pitches = len(set(pitches))\n",
    "        start_times = [note.start for note in notes]\n",
    "        unique_starts = len(set(start_times))\n",
    "        articulation_rate = unique_starts / total_time if total_time > 0 else 0\n",
    "\n",
    "        sorted_notes = sorted(notes, key=lambda n: n.start)\n",
    "        rest_time = 0.0\n",
    "        for i in range(1, len(sorted_notes)):\n",
    "            prev_end = sorted_notes[i-1].end\n",
    "            curr_start = sorted_notes[i].start\n",
    "            if curr_start > prev_end:\n",
    "                rest_time += curr_start - prev_end\n",
    "        rest_ratio = rest_time / total_time if total_time > 0 else 0\n",
    "\n",
    "        # polyphony\n",
    "        start_time_counts = {}\n",
    "        for note in notes:\n",
    "            t = round(note.start, 3)\n",
    "            start_time_counts[t] = start_time_counts.get(t,0) + 1\n",
    "        polyphonic_events = sum(1 for count in start_time_counts.values() if count > 1)\n",
    "        polyphony_ratio = polyphonic_events / len(start_time_counts) if start_time_counts else 0\n",
    "\n",
    "        # unique duration count\n",
    "        unique_durations = len(set(round(d, 3) for d in durations))\n",
    "\n",
    "        # longest rest\n",
    "        longest_rest = 0.0\n",
    "        for i in range(1, len(sorted_notes)):\n",
    "            gap = sorted_notes[i].start - sorted_notes[i-1].end\n",
    "            if gap > longest_rest:\n",
    "                longest_rest = gap\n",
    "\n",
    "\n",
    "        # note start times\n",
    "        onset_std = np.std(start_times) if len(start_times) > 1 else 0\n",
    "\n",
    "        # notes per beat\n",
    "        notes_per_beat = num_notes / midi_obj.ticks_per_beat if midi_obj.ticks_per_beat > 0 else 0\n",
    "\n",
    "        \n",
    "        # combined feature vector\n",
    "        features = [average_pitch, std_pitch, average_duration,\n",
    "                    std_duration, note_density, pitch_range] + hist + hist_intervals + [\n",
    "                        unique_pitches, articulation_rate, rest_ratio, \n",
    "                        polyphony_ratio, unique_durations, longest_rest,\n",
    "                        onset_std, notes_per_beat]\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "        \n",
    "        for k in d:\n",
    "            x = self.features(k)\n",
    "            x_scaled = self.scaler.transform([x]) # scale the test features\n",
    "            pred = self.model.predict(x_scaled)\n",
    "            predictions[k] = str(pred[0])\n",
    "            \n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions\n",
    "\n",
    "    # Train your model. Note that this function will not be called from the autograder:\n",
    "    # instead you should upload your saved model using save()\n",
    "    def train(self, path):\n",
    "        with open(path, 'r') as f:\n",
    "            train_json = eval(f.read())\n",
    "            \n",
    "        X_train = [self.features(k) for k in train_json]\n",
    "        y_train = [train_json[k] for k in train_json]\n",
    "\n",
    "        # normalize features\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "        X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X_scaled, y_train,\n",
    "        test_size=0.2,\n",
    "        stratify=y_train,\n",
    "        random_state=42\n",
    "        )\n",
    "\n",
    "        \n",
    "        # model = LogisticRegression(max_iter=1000)\n",
    "        rf = RandomForestClassifier(\n",
    "            n_estimators=100, \n",
    "            max_depth=8,\n",
    "            min_samples_leaf=3,\n",
    "            random_state=42)\n",
    "            \n",
    "        xgb = XGBClassifier(\n",
    "            objective='multi:softprob',\n",
    "            eval_metric='mlogloss',\n",
    "            use_label_encoder=False,\n",
    "            n_estimators=100,\n",
    "            max_depth=6,\n",
    "            learning_rate=0.1,\n",
    "            subsample=0.8,\n",
    "            colsample_bytree=0.8,\n",
    "            min_child_weight=3,\n",
    "            reg_alpha=1.0,\n",
    "            reg_lambda=2.0,\n",
    "            gamma=0.5,\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        final_model = LogisticRegression(max_iter=1000, C=0.5)\n",
    "        self.model = StackingClassifier(\n",
    "            estimators=[('rf', rf), ('xgb', xgb)],\n",
    "            final_estimator=final_model,\n",
    "            passthrough=False,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "        # self.model = StackingClassifier(\n",
    "        #     estimators=[('rf', rf),\n",
    "        #                 ('xgb', xgb)\n",
    "        #                ], \n",
    "        #     final_estimator=RandomForestClassifier(n_estimators=100, max_depth=6, random_state=42), n_jobs=-1)\n",
    "        \n",
    "        self.model.fit(X_tr, y_tr)\n",
    "\n",
    "        y_val_pred = self.model.predict(X_val)\n",
    "        val_acc = accuracy_score(y_val, y_val_pred)\n",
    "        print(f\"Validation accuracy = {val_acc:.4f}\")\n",
    "        \n",
    "        self.scaler = scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c83a314",
   "metadata": {},
   "source": [
    "## Task 2: Sequence prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cf9aaeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot2 = \"student_files/task2_next_sequence_prediction/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ac072a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model2():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get_first_last_pitch(self, path):\n",
    "        filepath = path if os.path.exists(path) else os.path.join(dataroot2, path)\n",
    "        notes = miditoolkit.midi.parser.MidiFile(filepath).instruments[0].notes\n",
    "\n",
    "        # print(\"loading Midi: \", path)\n",
    "        \n",
    "        if not notes:\n",
    "            return 0,0\n",
    "\n",
    "        sorted_notes = sorted(notes, key=lambda n: n.start)\n",
    "        return sorted_notes[0].pitch, sorted_notes[-1].pitch\n",
    "\n",
    "    def features(self, path):\n",
    "        # midi_obj = miditoolkit.midi.parser.MidiFile(dataroot2 + '/' + path)\n",
    "        filepath = path if os.path.exists(path) else os.path.join(dataroot2, path)\n",
    "        midi_obj = miditoolkit.midi.parser.MidiFile(filepath)\n",
    "        # print(\"loading Midi: \", path)\n",
    "        \n",
    "        notes = midi_obj.instruments[0].notes\n",
    "        if not notes:\n",
    "            return [0]*4\n",
    "\n",
    "        \n",
    "        num_notes = len(notes)\n",
    "        pitches = [note.pitch for note in notes]\n",
    "        durations = [note.end - note.start for note in notes]\n",
    "        total_time = max(note.end for note in notes) - min(note.start for note in notes)\n",
    "\n",
    "        # main features\n",
    "        average_pitch = sum([note.pitch for note in notes]) / num_notes\n",
    "        std_pitch = np.std(pitches)\n",
    "        average_duration = sum(durations) / num_notes\n",
    "        note_density = num_notes / total_time if total_time > 0 else 0\n",
    "        pitch_range = max(pitches) - min(pitches)\n",
    "\n",
    "        # rest ratio\n",
    "        sorted_notes = sorted(notes, key=lambda n: n.start)\n",
    "        rest_time = 0.0\n",
    "        for i in range(1, len(sorted_notes)):\n",
    "            gap = sorted_notes[i].start - sorted_notes[i-1].end\n",
    "            if gap > 0:\n",
    "                rest_time += gap\n",
    "        rest_ratio = rest_time / total_time if total_time > 0 else 0\n",
    "\n",
    "        # pitch class histogram\n",
    "        pitch_classes = [p%12 for p in pitches]\n",
    "        hist = [0] * 12\n",
    "        for classes in pitch_classes:\n",
    "            hist[classes] += 1 \n",
    "        hist = [x / num_notes for x in hist]\n",
    "\n",
    "        # interval histogram\n",
    "        intervals = [pitches[i+1] - pitches[i] for i in range(len(pitches) - 1)]\n",
    "        hist_intervals = [0] * 5\n",
    "        for interval in intervals:\n",
    "            if interval < -6:\n",
    "                hist_intervals[0] += 1\n",
    "            elif interval < 0:\n",
    "                hist_intervals[1] += 1\n",
    "            elif interval == 0:\n",
    "                hist_intervals[2] += 1\n",
    "            elif interval <= 6:\n",
    "                hist_intervals[3] += 1\n",
    "            else:\n",
    "                hist_intervals[4] += 1\n",
    "        hist_intervals = [x / len(intervals) for x in hist_intervals] if intervals else [0] * 5\n",
    "        \n",
    "        \n",
    "        features = [average_pitch, std_pitch, average_duration,\n",
    "                    note_density, pitch_range, rest_ratio] + hist + hist_intervals\n",
    "        return features\n",
    "    \n",
    "    def train(self, path):\n",
    "        # This baseline doesn't use any model (it just measures feature similarity)\n",
    "        # You can use this approach but *probably* you'll want to implement a model\n",
    "        with open(path, 'r') as f:\n",
    "            train_json = eval(f.read())\n",
    "\n",
    "        pairs = list(train_json.items())\n",
    "        train_pairs, val_pairs = train_test_split(pairs, test_size=0.15, random_state=42)\n",
    "\n",
    "        X_train = []\n",
    "        y_train = []\n",
    "\n",
    "        for (path1, path2), label in train_pairs:\n",
    "            x1 = self.features(path1)\n",
    "            x2 = self.features(path2)\n",
    "            diff = [a - b for a,b in zip(x1, x2)]\n",
    "\n",
    "            f1, l1 = self.get_first_last_pitch(path1)\n",
    "            f2, l2 = self.get_first_last_pitch(path2)\n",
    "            pitch_transition = [abs(f2 - l1)]\n",
    "\n",
    "            rhythm_similarity = [abs(x1[2] - x2[2])]\n",
    "            \n",
    "            combined = x1 + x2 + diff + pitch_transition + rhythm_similarity\n",
    "            X_train.append(combined)\n",
    "            y_train.append(label)\n",
    "\n",
    "        X_val = []\n",
    "        y_val = []\n",
    "        for (path1, path2), label in val_pairs:\n",
    "            x1 = self.features(path1)\n",
    "            x2 = self.features(path2)\n",
    "            diff = [a - b for a,b in zip(x1, x2)]\n",
    "            f1, l1 = self.get_first_last_pitch(path1)\n",
    "            f2, l2 = self.get_first_last_pitch(path2)\n",
    "            pitch_transition = [abs(f2 - l1)]\n",
    "            rhythm_similarity = [abs(x1[2] - x2[2])]\n",
    "            combined = x1 + x2 + diff + pitch_transition + rhythm_similarity\n",
    "            X_val.append(combined)\n",
    "            y_val.append(label)\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(X_train)\n",
    "        X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "        model = RandomForestClassifier(n_estimators=100, max_depth=15, random_state=42)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "\n",
    "        val_preds = model.predict(X_val_scaled)\n",
    "        val_acc = accuracy_score(y_val, val_preds)\n",
    "\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def predict(self, path, outpath=None):\n",
    "        d = eval(open(path, 'r').read())\n",
    "        predictions = {}\n",
    "        for k in d:\n",
    "            path1,path2 = k # Keys are pairs of paths\n",
    "            x1 = self.features(path1)\n",
    "            x2 = self.features(path2)\n",
    "            diff = [a - b for a,b in zip(x1,x2)]\n",
    "            # pitch transition\n",
    "            f1, l1 = self.get_first_last_pitch(path1)\n",
    "            f2, l2 = self.get_first_last_pitch(path2)\n",
    "            pitch_transition = [f2 - l1]\n",
    "            rhythm_similarity = [abs(x1[2] - x2[2])]\n",
    "            combined = x1 + x2 + diff + pitch_transition + rhythm_similarity\n",
    "            \n",
    "            x_scaled = self.scaler.transform([combined])\n",
    "            pred = self.model.predict(x_scaled)\n",
    "            predictions[k] = bool(pred[0])\n",
    "            \n",
    "            # # Note: hardcoded difference between features\n",
    "            # if abs(x1[0] - x2[0]) < 5:\n",
    "            #     predictions[k] = True\n",
    "            # else:\n",
    "            #     predictions[k] = False\n",
    "        \n",
    "        if outpath:\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36bf2cf",
   "metadata": {},
   "source": [
    "## Task 3: Audio classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ab1c5c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some constants (you can change any of these if useful)\n",
    "SAMPLE_RATE = 16000\n",
    "N_MELS = 64\n",
    "N_CLASSES = 10\n",
    "AUDIO_DURATION = 10 # seconds\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b94c0b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataroot3 = \"student_files/task3_audio_classification/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5cb1e46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_waveform(path):\n",
    "    waveform, sr = librosa.load(dataroot3 + '/' + path, sr=SAMPLE_RATE)\n",
    "    waveform = np.array([waveform])\n",
    "    if sr != SAMPLE_RATE:\n",
    "        resample = torchaudio.transforms.Resample(orig_freq=sr, new_freq=SAMPLE_RATE)\n",
    "        waveform = resample(waveform)\n",
    "    # Pad so that everything is the right length\n",
    "    target_len = SAMPLE_RATE * AUDIO_DURATION\n",
    "    if waveform.shape[1] < target_len:\n",
    "        pad_len = target_len - waveform.shape[1]\n",
    "        waveform = F.pad(waveform, (0, pad_len))\n",
    "    else:\n",
    "        waveform = waveform[:, :target_len]\n",
    "    waveform = torch.FloatTensor(waveform)\n",
    "    return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18660271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(Dataset):\n",
    "    def __init__(self, meta, preload = True):\n",
    "        self.meta = meta\n",
    "        ks = list(meta.keys())\n",
    "        self.idToPath = dict(zip(range(len(ks)), ks))\n",
    "        self.pathToFeat = {}\n",
    "\n",
    "        self.mel = MelSpectrogram(sample_rate=SAMPLE_RATE, n_mels=N_MELS)\n",
    "        self.db = AmplitudeToDB()\n",
    "        \n",
    "        self.preload = preload # Determines whether the features should be preloaded (uses more memory)\n",
    "                               # or read from disk / computed each time (slow if your system is i/o-bound)\n",
    "        if self.preload:\n",
    "            for path in ks:\n",
    "                waveform = extract_waveform(path)\n",
    "                mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "                self.pathToFeat[path] = mel_spec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.meta)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Faster version, preloads the features\n",
    "        path = self.idToPath[idx]\n",
    "        tags = self.meta[path]\n",
    "        bin_label = torch.tensor([1 if tag in tags else 0 for tag in TAGS], dtype=torch.float32)\n",
    "\n",
    "        if self.preload:\n",
    "            mel_spec = self.pathToFeat[path]\n",
    "        else:\n",
    "            waveform = extract_waveform(path)\n",
    "            mel_spec = self.db(self.mel(waveform)).squeeze(0)\n",
    "        \n",
    "        return mel_spec.unsqueeze(0), bin_label, path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ce87ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Loaders():\n",
    "    def __init__(self, train_path, test_path, split_ratio=0.9, seed = 0):\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "        \n",
    "        meta_train = eval(open(train_path, 'r').read())\n",
    "        l_test = eval(open(test_path, 'r').read())\n",
    "        meta_test = dict([(x,[]) for x in l_test]) # Need a dictionary for the above class\n",
    "        \n",
    "        all_train = AudioDataset(meta_train)\n",
    "        test_set = AudioDataset(meta_test)\n",
    "        \n",
    "        # Split all_train into train + valid\n",
    "        total_len = len(all_train)\n",
    "        train_len = int(total_len * split_ratio)\n",
    "        valid_len = total_len - train_len\n",
    "        train_set, valid_set = random_split(all_train, [train_len, valid_len])\n",
    "        \n",
    "        self.loaderTrain = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "        self.loaderValid = DataLoader(valid_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "        self.loaderTest = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "14d78705",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=N_CLASSES):\n",
    "        super(CNNClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(32 * (N_MELS // 4) * (801 // 4), 256)\n",
    "        self.fc2 = nn.Linear(256, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 16, mel/2, time/2)\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, mel/4, time/4)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        return torch.sigmoid(self.fc2(x))  # multilabel → sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fbaf4d1-7b67-457a-b080-50b7f45ba2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, n_classes=N_CLASSES):\n",
    "        super(ResNetClassifier, self).__init__()\n",
    "        self.model = resnet18(pretrained=True)\n",
    "\n",
    "        # Modify the first conv layer to accept 1-channel input instead of 3\n",
    "        self.model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        # Replace the final fully connected layer\n",
    "        self.model.fc = nn.Sequential(\n",
    "            nn.Linear(self.model.fc.in_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, n_classes),\n",
    "            nn.Sigmoid()  # Use sigmoid for multilabel classification\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e634810",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline():\n",
    "    def __init__(self, model, learning_rate, seed = 0):\n",
    "        # These two lines will (mostly) make things deterministic.\n",
    "        # You're welcome to modify them to try to get a better solution.\n",
    "        torch.manual_seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        self.device = torch.device(\"cpu\") # Can change this if you have a GPU, but the autograder will use CPU\n",
    "        self.model = model.to(self.device) #model.cuda() # Also uncomment these lines for GPU\n",
    "        self.optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "        self.criterion = nn.BCELoss()\n",
    "\n",
    "    def evaluate(self, loader, threshold=0.5, outpath=None):\n",
    "        self.model.eval()\n",
    "        preds, targets, paths = [], [], []\n",
    "        with torch.no_grad():\n",
    "            for x, y, ps in loader:\n",
    "                x = x.to(self.device) #x.cuda()\n",
    "                y = y.to(self.device) #y.cuda()\n",
    "                outputs = self.model(x)\n",
    "                preds.append(outputs.cpu())\n",
    "                targets.append(y.cpu())\n",
    "                paths += list(ps)\n",
    "        \n",
    "        preds = torch.cat(preds)\n",
    "        targets = torch.cat(targets)\n",
    "        preds_bin = (preds > threshold).float()\n",
    "        \n",
    "        predictions = {}\n",
    "        for i in range(preds_bin.shape[0]):\n",
    "            predictions[paths[i]] = [TAGS[j] for j in range(len(preds_bin[i])) if preds_bin[i][j]]\n",
    "        \n",
    "        mAP = None\n",
    "        if outpath: # Save predictions\n",
    "            with open(outpath, \"w\") as z:\n",
    "                z.write(str(predictions) + '\\n')\n",
    "        else: # Only compute accuracy if we're *not* saving predictions, since we can't compute test accuracy\n",
    "            mAP = average_precision_score(targets, preds, average='macro')\n",
    "        return predictions, mAP\n",
    "\n",
    "    def train(self, train_loader, val_loader, num_epochs):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            running_loss = 0.0\n",
    "            for x, y, path in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "                x = x.to(self.device) #x.cuda()\n",
    "                y = y.to(self.device) #y.cuda()\n",
    "                self.optimizer.zero_grad()\n",
    "                outputs = self.model(x)\n",
    "                loss = self.criterion(outputs, y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "            val_predictions, mAP = self.evaluate(val_loader)\n",
    "            print(f\"[Epoch {epoch+1}] Loss: {running_loss/len(train_loader):.4f} | Val mAP: {mAP:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87197d0",
   "metadata": {},
   "source": [
    "## Run everything..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "9708d27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run1():\n",
    "    model = model1()\n",
    "    model.train(dataroot1 + \"/train.json\")\n",
    "    train_preds = model.predict(dataroot1 + \"/train.json\")\n",
    "    test_preds = model.predict(dataroot1 + \"/test.json\", \"predictions1.json\")\n",
    "    \n",
    "    train_labels = eval(open(dataroot1 + \"/train.json\").read())\n",
    "    acc1 = accuracy1(train_labels, train_preds)\n",
    "    print(\"Task 1 training accuracy = \" + str(acc1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9cb50b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run2():\n",
    "    model = model2()\n",
    "    model.train(dataroot2 + \"/train.json\")\n",
    "    train_preds = model.predict(dataroot2 + \"/train.json\")\n",
    "    test_preds = model.predict(dataroot2 + \"/test.json\", \"predictions2.json\")\n",
    "    \n",
    "    train_labels = eval(open(dataroot2 + \"/train.json\").read())\n",
    "    acc2 = accuracy2(train_labels, train_preds)\n",
    "    print(\"Task 2 training accuracy = \" + str(acc2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3dbe7141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run3():\n",
    "    loaders = Loaders(dataroot3 + \"/train.json\", dataroot3 + \"/test.json\")\n",
    "    model = ResNetClassifier()\n",
    "    pipeline = Pipeline(model, 1e-4)\n",
    "    \n",
    "    pipeline.train(loaders.loaderTrain, loaders.loaderValid, 5)\n",
    "    train_preds, train_mAP = pipeline.evaluate(loaders.loaderTrain, 0.5)\n",
    "    valid_preds, valid_mAP = pipeline.evaluate(loaders.loaderValid, 0.5)\n",
    "    test_preds, _ = pipeline.evaluate(loaders.loaderTest, 0.5, \"predictions3.json\")\n",
    "    \n",
    "    all_train = eval(open(dataroot3 + \"/train.json\").read())\n",
    "    for k in valid_preds:\n",
    "        # We split our training set into train+valid\n",
    "        # so need to remove validation instances from the training set for evaluation\n",
    "        all_train.pop(k)\n",
    "    acc3 = accuracy3(all_train, train_preds)\n",
    "    print(\"Task 3 training mAP = \" + str(acc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "458d6570",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulbulsara/anaconda3/envs/asmt1/lib/python3.10/site-packages/xgboost/training.py:183: UserWarning: [14:58:41] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1747336884418/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "[14:58:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1747336884418/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[14:58:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1747336884418/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[14:58:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1747336884418/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[14:58:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1747336884418/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "[14:58:42] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1747336884418/work/src/learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy = 0.7355\n",
      "Task 1 training accuracy = 0.9239669421487603\n"
     ]
    }
   ],
   "source": [
    "run1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f0286c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 training accuracy = 0.9657878217200251\n"
     ]
    }
   ],
   "source": [
    "run2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774f2c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulbulsara/anaconda3/envs/asmt1/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/Users/rahulbulsara/anaconda3/envs/asmt1/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /Users/rahulbulsara/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|████████████████████████████████████████| 44.7M/44.7M [00:07<00:00, 6.39MB/s]\n",
      "Epoch 1:  25%|████████▏                        | 28/113 [28:13<1:25:51, 60.60s/it]"
     ]
    }
   ],
   "source": [
    "run3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a8b523",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "153 (asmt1)",
   "language": "python",
   "name": "asmt1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
